{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T10:46:40.643402Z",
     "start_time": "2025-02-08T10:46:40.639814Z"
    }
   },
   "source": [
    "# 导入需要的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from torch import nn,optim\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import  SVC\n",
    "\n",
    "# matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# matplotlib.rcParams['axes.unicode_minus'] = False\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T10:46:46.706964Z",
     "start_time": "2025-02-08T10:46:46.704535Z"
    }
   },
   "source": [
    "# 定义一个函数来读取arff文件\n",
    "def read_arff(file):            \n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        header = []\n",
    "        for line in f:\n",
    "            if line.startswith(\"@attribute\"):\n",
    "                header.append(line.split()[1])\n",
    "            elif line.startswith(\"@data\"):\n",
    "                break\n",
    "        df = pd.read_csv(f, header=None)\n",
    "        df.columns = header\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T10:46:48.097307Z",
     "start_time": "2025-02-08T10:46:47.907305Z"
    }
   },
   "source": [
    "# 数据有多种格式。我们将把arff文件加载到Pandas数据帧中:\n",
    "train=read_arff('KDDTrain+.arff')\n",
    "test=read_arff('KDDTest+.arff')\n",
    "# 输出数据的shape\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 42)\n",
      "(22544, 42)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T10:46:49.361235Z",
     "start_time": "2025-02-08T10:46:49.309345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_list=['train','test']\n",
    "y_list=[train.shape[0],test.shape[0]]\n",
    "x = range(len(label_list))\n",
    "plt.bar(x,y_list)  # 画出训练集和测试集的数量分布柱状图\n",
    "plt.xticks([index+0.2 for index in x], label_list)\n",
    "plt.xlabel(\"数据集\")\n",
    "plt.ylabel('数量')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '数量')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) Arial.\n",
      "  func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Glyph 25454 (\\N{CJK UNIFIED IDEOGRAPH-636E}) missing from font(s) Arial.\n",
      "  func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Glyph 38598 (\\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from font(s) Arial.\n",
      "  func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) Arial.\n",
      "  func(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:30:34.417550Z",
     "start_time": "2025-02-08T08:30:34.398902Z"
    }
   },
   "source": [
    "# 我们将把训练和测试数据合并成一个数据帧。这将给我们更多的数据来训练我们的自动编码器。我们也会重组:\n",
    "df = train.append(test)\n",
    "print(df.shape)\n",
    "#df = df.sample(frac=1.0) # 打乱数据顺序，保证随机性\n",
    "df.head(10)"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/f1/4mbg7sls3dd69qxhfw_r0k0m0000gn/T/ipykernel_16552/3856558780.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# 我们将把训练和测试数据合并成一个数据帧。这将给我们更多的数据来训练我们的自动编码器。我们也会重组:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#df = df.sample(frac=1.0) # 打乱数据顺序，保证随机性\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/vscode/development/python/lib/python3.12/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   6295\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6296\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6297\u001B[0m         \u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6298\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6299\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 开始热编码操作\n",
    "protocol_type_list=list(df[\"'protocol_type'\"])\n",
    "service_list=list(df[\"'service'\"])\n",
    "flag_list=list(df[\"'flag'\"])\n",
    "\n",
    "#将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据\n",
    "def find_index(x,y):\n",
    "    return [i for i in range(len(y)) if y[i]==x]\n",
    "\n",
    "#定义将源文件行中3种协议类型转换成数字标识的函数\n",
    "def handleProtocol(inputlist):\n",
    "    protocol_list=['tcp','udp','icmp']\n",
    "    new_protocol_list=[]\n",
    "    for x in inputlist:\n",
    "        if x in protocol_list:\n",
    "            new_protocol_list.append(find_index(x,protocol_list)[0]) # 第0维返回的是热编码\n",
    "    return new_protocol_list\n",
    "\n",
    "#定义将源文件行中70种网络服务类型转换成数字标识的函数\n",
    "def handleService(inputlist):\n",
    "    service_list=['aol','auth','bgp','courier','csnet_ns','ctf','daytime','discard','domain','domain_u',\n",
    "                 'echo','eco_i','ecr_i','efs','exec','finger','ftp','ftp_data','gopher','harvest','hostnames',\n",
    "                 'http','http_2784','http_443','http_8001','imap4','IRC','iso_tsap','klogin','kshell','ldap',\n",
    "                 'link','login','mtp','name','netbios_dgm','netbios_ns','netbios_ssn','netstat','nnsp','nntp',\n",
    "                 'ntp_u','other','pm_dump','pop_2','pop_3','printer','private','red_i','remote_job','rje','shell',\n",
    "                 'smtp','sql_net','ssh','sunrpc','supdup','systat','telnet','tftp_u','tim_i','time','urh_i','urp_i',\n",
    "                 'uucp','uucp_path','vmnet','whois','X11','Z39_50']\n",
    "    new_service_list=[]\n",
    "    for x in inputlist:\n",
    "        if x in service_list:\n",
    "            new_service_list.append(find_index(x,service_list)[0])\n",
    "    return new_service_list\n",
    "\n",
    "\n",
    "#定义将源文件行中11种网络连接状态转换成数字标识的函数\n",
    "def handleFlag(inputlist):\n",
    "    flag_list=['OTH','REJ','RSTO','RSTOS0','RSTR','S0','S1','S2','S3','SF','SH']\n",
    "    new_flag_list=[]\n",
    "    for x in inputlist:\n",
    "        if x in flag_list:\n",
    "            new_flag_list.append(find_index(x,flag_list)[0])\n",
    "    return new_flag_list\n",
    " \n",
    "    \n",
    "    \n",
    "protocol_type_list=handleProtocol(protocol_type_list)\n",
    "service_list=handleService(service_list)\n",
    "flag_list=handleFlag(flag_list)\n",
    "\n",
    "\n",
    "# 更新'protocol_type'  'service' 'flag' 三列数据\n",
    "df[\"'protocol_type'\"]=protocol_type_list\n",
    "df[\"'service'\"]=service_list\n",
    "df[\"'flag'\"]=flag_list\n",
    "\n",
    "# 热编码后的数据\n",
    "df.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df1=df.iloc[0:70000] # 前70000条用作自编码器模型的数据包含正常和不正常\n",
    "df2=df.iloc[70000:]  #后70000条用做SVM的数据，包含正常和不正常\n",
    "\n",
    "print(len(df2))\n",
    "newindex=[i for i in range(0,78517)]\n",
    "df2.index=pd.Series(newindex)\n",
    "df2.tail(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#  开始进行自编码器模型实验\n",
    "new_columns = list(df1.columns)\n",
    "new_columns[-1] = 'target'\n",
    "df1.columns = new_columns\n",
    " # 无监督学习，不需要目标列\n",
    "normal_df = df1[df1.target == \"normal\"].drop(labels='target', axis=1)  # 正常数据\n",
    "print(normal_df.shape) \n",
    "anomaly_df = df1[df1.target != \"normal\"].drop(labels='target', axis=1)  # 异常数据\n",
    "print(anomaly_df.shape)\n",
    "normal_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 标准化和最小最大化数据\n",
    "z_scaler= preprocessing.StandardScaler()\n",
    "normal_df=z_scaler.fit_transform(normal_df)\n",
    "anomaly_df=z_scaler.fit_transform(anomaly_df)\n",
    "\n",
    "m_scaler = preprocessing.MinMaxScaler()\n",
    "normal_df = m_scaler.fit_transform(normal_df)\n",
    "anomaly_df = m_scaler.fit_transform(anomaly_df)\n",
    "\n",
    "print(normal_df)\n",
    "print(\"#\"*100)\n",
    "print(anomaly_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 正常数据集划分为训练集、验证集、测试集\n",
    "train_df, val_df = train_test_split(\n",
    "  normal_df,\n",
    "  test_size=0.15, # 划分比例\n",
    "  random_state=1\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "  val_df,\n",
    "  test_size=0.33,\n",
    "  random_state=1\n",
    ")\n",
    "\n",
    "print(train_df.shape)  #  正常训练集数量\n",
    "print(val_df.shape)   # 正常验证集数量\n",
    "print(test_df.shape)  # 正常测试集数量\n",
    "\n",
    "\n",
    "anomaly_df=anomaly_df.reshape(-1,1,41) # 异常测试集数量\n",
    "print(anomaly_df.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 将数据变成30923*1*41的形状\n",
    "train_df=train_df.reshape(-1,1,41) \n",
    "val_df=val_df.reshape(-1,1,41)\n",
    "test_df=test_df.reshape(-1,1,41)\n",
    "print(train_df.shape)  #  正常训练集数量\n",
    "print(val_df.shape)   # 正常验证集数量\n",
    "print(test_df.shape)  # 正常测试集数量\n",
    "print(type(train_df))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:17.933850Z",
     "start_time": "2024-07-01T13:30:17.866917Z"
    }
   },
   "source": [
    "# 将数据转化为张量\n",
    "def create_dataset(df):\n",
    "  sequences = df.tolist() \n",
    "  dataset = [torch.tensor(s).float() for s in sequences]\n",
    "  n_seq, seq_len, n_features = torch.stack(dataset).shape\n",
    "  return dataset, seq_len, n_features\n",
    "\n",
    "train_dataset, seq_len, n_features = create_dataset(train_df) # 正常训练集\n",
    "val_dataset, _, _ = create_dataset(val_df) # 正常验证集\n",
    "\n",
    "test_normal_dataset, _, _ = create_dataset(test_df)  #  正常测试集\n",
    "test_anomaly_dataset, _, _ = create_dataset(anomaly_df) # 异常测试集"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m   n_seq, seq_len, n_features \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(dataset)\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dataset, seq_len, n_features\n\u001B[0;32m----> 8\u001B[0m train_dataset, seq_len, n_features \u001B[38;5;241m=\u001B[39m create_dataset(\u001B[43mtrain_df\u001B[49m) \u001B[38;5;66;03m# 正常训练集\u001B[39;00m\n\u001B[1;32m      9\u001B[0m val_dataset, _, _ \u001B[38;5;241m=\u001B[39m create_dataset(val_df) \u001B[38;5;66;03m# 正常验证集\u001B[39;00m\n\u001B[1;32m     11\u001B[0m test_normal_dataset, _, _ \u001B[38;5;241m=\u001B[39m create_dataset(test_df)  \u001B[38;5;66;03m#  正常测试集\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.132243Z",
     "start_time": "2024-07-01T13:30:18.129387Z"
    }
   },
   "source": [
    "# 自编码器模型\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.rnn_en1 = torch.nn.LSTM(  #41->20\n",
    "            input_size=41,\n",
    "            hidden_size=20,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.rnn_en2 = torch.nn.LSTM(  #20->10\n",
    "            input_size=20,\n",
    "            hidden_size=10,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.out = torch.nn.Linear(in_features=10, out_features=2) # 10->2\n",
    "\n",
    "\n",
    "        self.rnn_de1 = torch.nn.LSTM(  # 2->10\n",
    "            input_size=2,\n",
    "            hidden_size=10,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.rnn_de2 = torch.nn.LSTM(  # 10->20\n",
    "            input_size=10,\n",
    "            hidden_size=20,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out_2 = torch.nn.Linear(in_features=20, out_features=41) # 20->41\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (h_n, c_n) = self.rnn_en1(x) # 41->20\n",
    "        output,(h_n, c_n)=self.rnn_en2(output.view(-1,1,20)) # 20->10\n",
    "        encode = self.out(output) # 10->3\n",
    "\n",
    "        output1, (h_n1, c_n1) = self.rnn_de1(encode.view(-1, 1, 2)) # 2->10\n",
    "        output1,(h_n1, c_n1)=self.rnn_de2(output1.view(-1, 1, 10)) # 10->20\n",
    "        decode = self.out_2(output1) # 20->41\n",
    "\n",
    "        encode=encode.squeeze(-1)\n",
    "        decode=decode.squeeze(-1)\n",
    "        return encode, decode"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.482284Z",
     "start_time": "2024-07-01T13:30:18.463954Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 模型加载\n",
    "model = AutoEncoder()\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.510540Z",
     "start_time": "2024-07-01T13:30:18.507051Z"
    }
   },
   "source": [
    "# 训练模型\n",
    "def train_model(model, train_dataset, val_dataset, n_epochs):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # 优化器\n",
    "  criterion = nn.MSELoss(reduction='sum').to(device) # 损失函数使用MSE\n",
    "  history = dict(train=[], val=[])  # 记录训练数据的误差损失和验证集的误差损失\n",
    "  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "  best_loss = 10000.0  # 初始化最大损失\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    model = model.train()  # 切换到训练模式\n",
    "    train_losses = []  # 训练误差\n",
    "    for seq_true in train_dataset:\n",
    "      optimizer.zero_grad()  # 梯度清零\n",
    "      seq_true = seq_true.to(device)\n",
    "      seq_compressed,seq_pred = model(seq_true.view(-1,1,41))  # 获得压缩后的数据和还原的数据\n",
    "      loss = criterion(seq_pred, seq_true.view(-1,1,41)) # 求原始数据和还原后的数据的重构误差损失\n",
    "      loss.backward()  # 误差反向传播\n",
    "      optimizer.step()  # 更新参数\n",
    "      train_losses.append(loss.item())\n",
    "    val_losses = []\n",
    "    model = model.eval() # 切换到eval模式  不需要梯度更新\n",
    "    with torch.no_grad():  # 不需要梯度\n",
    "      for seq_true in val_dataset:  # 验证集 防止过拟合\n",
    "        # seq_true=seq_true.view(-1,1,41)\n",
    "        seq_true = seq_true.to(device)\n",
    "        _,seq_pred = model(seq_true.view(-1,1,41))\n",
    "        loss = criterion(seq_pred, seq_true.view(-1,1,41))  # 验证集误差\n",
    "        val_losses.append(loss.item())\n",
    "    train_loss = np.mean(train_losses) # 取误差平均\n",
    "    val_loss = np.mean(val_losses)\n",
    "    history['train'].append(train_loss)\n",
    "    history['val'].append(val_loss)\n",
    "    if val_loss < best_loss: # 更新损失误差\n",
    "      best_loss = val_loss\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "  model.load_state_dict(best_model_wts)\n",
    "  return model.eval(), history"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.531038Z",
     "start_time": "2024-07-01T13:30:18.523394Z"
    }
   },
   "source": [
    "model, history = train_model(\n",
    "  model,\n",
    "  train_dataset,\n",
    "  val_dataset,\n",
    "  n_epochs=100\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model, history \u001B[38;5;241m=\u001B[39m train_model(\n\u001B[1;32m      2\u001B[0m   model,\n\u001B[0;32m----> 3\u001B[0m   \u001B[43mtrain_dataset\u001B[49m,\n\u001B[1;32m      4\u001B[0m   val_dataset,\n\u001B[1;32m      5\u001B[0m   n_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      6\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.572652Z",
     "start_time": "2024-07-01T13:30:18.531839Z"
    }
   },
   "source": [
    "# 加载训练好的模型\n",
    "model = torch.load('LSTM_2020_6_1_two_dimensions.pth')\n",
    "model = model.to(device)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LSTM_2020_6_1_two_dimensions.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 加载训练好的模型\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLSTM_2020_6_1_two_dimensions.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/Documents/vscode/development/python/lib/python3.12/site-packages/torch/serialization.py:997\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    995\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 997\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    998\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    999\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m   1000\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m   1001\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/Documents/vscode/development/python/lib/python3.12/site-packages/torch/serialization.py:444\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 444\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/Documents/vscode/development/python/lib/python3.12/site-packages/torch/serialization.py:425\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 425\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'LSTM_2020_6_1_two_dimensions.pth'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.573289Z",
     "start_time": "2024-07-01T13:30:18.573234Z"
    }
   },
   "source": [
    "model.eval()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.591313Z",
     "start_time": "2024-07-01T13:30:18.582090Z"
    }
   },
   "source": [
    "#  随着训练次数的增加 train_loss和val_loss的分布情况，曲线大致相近\n",
    "x=[i for i in range(1,101)]\n",
    "y1=history['train']\n",
    "y2=history['val']\n",
    "\n",
    "plt.plot(x, y1, label='train_loss')\n",
    "plt.plot(x, y2, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()  # 画出训练集和验证集的误差损失分布\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#  随着训练次数的增加 train_loss和val_loss的分布情况，曲线大致相近\u001B[39;00m\n\u001B[1;32m      2\u001B[0m x\u001B[38;5;241m=\u001B[39m[i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m101\u001B[39m)]\n\u001B[0;32m----> 3\u001B[0m y1\u001B[38;5;241m=\u001B[39m\u001B[43mhistory\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      4\u001B[0m y2\u001B[38;5;241m=\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(x, y1, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.612721Z",
     "start_time": "2024-07-01T13:30:18.611178Z"
    }
   },
   "source": [
    "# # # 保存模型\n",
    "# MODEL_PATH = 'LSTM_2020_6_1_two_dimensions.pth'\n",
    "# torch.save(model, MODEL_PATH)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.643349Z",
     "start_time": "2024-07-01T13:30:18.641187Z"
    }
   },
   "source": [
    "# 用训练好的模型来预测\n",
    "def predict(model, dataset):\n",
    "  compressed,predictions, losses = [], [],[]\n",
    "  criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "  with torch.no_grad():\n",
    "    model = model.eval()\n",
    "    for seq_true in dataset:\n",
    "      seq_true=seq_true.view(-1,1,41)\n",
    "      seq_true = seq_true.to(device)\n",
    "      seq_compressed,seq_pred = model(seq_true)\n",
    "      loss = criterion(seq_pred, seq_true)\n",
    "      predictions.append(seq_pred.cpu().numpy().flatten())\n",
    "      compressed.append(seq_compressed.cpu().numpy().flatten())\n",
    "      losses.append(loss.item())\n",
    "  return  compressed,predictions, losses"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.677798Z",
     "start_time": "2024-07-01T13:30:18.670020Z"
    }
   },
   "source": [
    "# 绘制正常训练集重构损失核函数图\n",
    "_,_, losses = predict(model, train_dataset)\n",
    "sns.distplot(losses, bins=50, kde=True);"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 绘制正常训练集重构损失核函数图\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m _,_, losses \u001B[38;5;241m=\u001B[39m predict(model, \u001B[43mtrain_dataset\u001B[49m)\n\u001B[1;32m      3\u001B[0m sns\u001B[38;5;241m.\u001B[39mdistplot(losses, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, kde\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m);\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.701216Z",
     "start_time": "2024-07-01T13:30:18.694197Z"
    }
   },
   "source": [
    "# 绘制正常测试集重构损失核函数图  \n",
    "_,predictions, pred_losses1 = predict(model, test_normal_dataset)\n",
    "sns.distplot(pred_losses1, bins=50, kde=True);"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_normal_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 绘制正常测试集重构损失核函数图  \u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m _,predictions, pred_losses1 \u001B[38;5;241m=\u001B[39m predict(model, \u001B[43mtest_normal_dataset\u001B[49m)\n\u001B[1;32m      3\u001B[0m sns\u001B[38;5;241m.\u001B[39mdistplot(pred_losses1, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, kde\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m);\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test_normal_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.738741Z",
     "start_time": "2024-07-01T13:30:18.731608Z"
    }
   },
   "source": [
    "# 输出训练集  测试集损失误差的平均值\n",
    "print(np.mean(losses))\n",
    "print(np.mean(pred_losses1))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 输出训练集  测试集损失误差的平均值\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39mmean(\u001B[43mlosses\u001B[49m))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39mmean(pred_losses1))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'losses' is not defined"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.754086Z",
     "start_time": "2024-07-01T13:30:18.746665Z"
    }
   },
   "source": [
    "# 验证异常测试数据  \n",
    "anomaly_dataset = test_anomaly_dataset[:len(test_normal_dataset)]  # 选择和正常测试集一样的数据量\n",
    "_,predictions, pred_losses2 = predict(model, anomaly_dataset)\n",
    "sns.distplot(pred_losses2, bins=50, kde=True)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_anomaly_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 验证异常测试数据  \u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m anomaly_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtest_anomaly_dataset\u001B[49m[:\u001B[38;5;28mlen\u001B[39m(test_normal_dataset)]  \u001B[38;5;66;03m# 选择和正常测试集一样的数据量\u001B[39;00m\n\u001B[1;32m      3\u001B[0m _,predictions, pred_losses2 \u001B[38;5;241m=\u001B[39m predict(model, anomaly_dataset)\n\u001B[1;32m      4\u001B[0m sns\u001B[38;5;241m.\u001B[39mdistplot(pred_losses2, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, kde\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test_anomaly_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.773280Z",
     "start_time": "2024-07-01T13:30:18.765576Z"
    }
   },
   "source": [
    "# 将正常数据测试集和异常数据测试集的误差分布放到一个图中\n",
    "recon_err_test_normal = pred_losses1\n",
    "recon_err_test_anomaly = pred_losses2\n",
    "sns.kdeplot(recon_err_test_normal,shade=True)\n",
    "sns.kdeplot(recon_err_test_anomaly,shade=True)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_losses1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 将正常数据测试集和异常数据测试集的误差分布放到一个图中\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m recon_err_test_normal \u001B[38;5;241m=\u001B[39m \u001B[43mpred_losses1\u001B[49m\n\u001B[1;32m      3\u001B[0m recon_err_test_anomaly \u001B[38;5;241m=\u001B[39m pred_losses2\n\u001B[1;32m      4\u001B[0m sns\u001B[38;5;241m.\u001B[39mkdeplot(recon_err_test_normal,shade\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pred_losses1' is not defined"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.807292Z",
     "start_time": "2024-07-01T13:30:18.797385Z"
    }
   },
   "source": [
    "threshold_range=np.linspace(0,8,1000) # 根据上图将可能取到的阈值区间划分为1000份\n",
    "correct_rate_test_noraml=0\n",
    "correct_rate_test_anomaly=0\n",
    "acc_list=[]\n",
    "rate_normal=[]\n",
    "rate_anomaly=[]\n",
    "for t in threshold_range:  # 计算不同阈值下正常数据被判断正确的概率和异常数据被判断正确的概率\n",
    "    correct_rate_test_noraml=(sum(l <= t for l in pred_losses1)/len(test_normal_dataset))\n",
    "    correct_rate_test_anomaly=(sum(l > t for l in pred_losses2)/len(test_normal_dataset))\n",
    "    rate_normal.append(correct_rate_test_noraml)\n",
    "    rate_anomaly.append(correct_rate_test_anomaly)\n",
    "\n",
    "    \n",
    "plt.plot(threshold_range, rate_normal, label='accuracy_normal')\n",
    "plt.plot(threshold_range, rate_anomaly, label='accuracy_anomaly')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"6.svg\")\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_losses1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m rate_anomaly\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m threshold_range:  \u001B[38;5;66;03m# 计算不同阈值下正常数据被判断正确的概率和异常数据被判断正确的概率\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m     correct_rate_test_noraml\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28msum\u001B[39m(l \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m t \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpred_losses1\u001B[49m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_normal_dataset))\n\u001B[1;32m      9\u001B[0m     correct_rate_test_anomaly\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28msum\u001B[39m(l \u001B[38;5;241m>\u001B[39m t \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m pred_losses2)\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_normal_dataset))\n\u001B[1;32m     10\u001B[0m     rate_normal\u001B[38;5;241m.\u001B[39mappend(correct_rate_test_noraml)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pred_losses1' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.835924Z",
     "start_time": "2024-07-01T13:30:18.828610Z"
    }
   },
   "source": [
    "df2 # 再用df2来检测以下我们的的自编码器模型"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf2\u001B[49m \u001B[38;5;66;03m# 再用df2来检测以下我们的的自编码器模型\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df2' is not defined"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.878648Z",
     "start_time": "2024-07-01T13:30:18.870488Z"
    }
   },
   "source": [
    "X_NormalAndAnomaly=df2.iloc[:,0:-1]  #  取除了label外的列\n",
    "Y_NormalAndAnomaly=df2.iloc[:,-1]    #  只取label列\n",
    "\n",
    "z_scaler= preprocessing.StandardScaler()  # 标准化\n",
    "X_NormalAndAnomaly=z_scaler.fit_transform(X_NormalAndAnomaly)\n",
    "\n",
    "\n",
    "m_scaler = preprocessing.MinMaxScaler()  # 最大最小化\n",
    "X_NormalAndAnomaly = m_scaler.fit_transform(X_NormalAndAnomaly)\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_NormalAndAnomaly\u001B[38;5;241m=\u001B[39m\u001B[43mdf2\u001B[49m\u001B[38;5;241m.\u001B[39miloc[:,\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m#  取除了label外的列\u001B[39;00m\n\u001B[1;32m      2\u001B[0m Y_NormalAndAnomaly\u001B[38;5;241m=\u001B[39mdf2\u001B[38;5;241m.\u001B[39miloc[:,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]    \u001B[38;5;66;03m#  只取label列\u001B[39;00m\n\u001B[1;32m      4\u001B[0m z_scaler\u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mStandardScaler()  \u001B[38;5;66;03m# 标准化\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df2' is not defined"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.935147Z",
     "start_time": "2024-07-01T13:30:18.913739Z"
    }
   },
   "source": [
    "X_NormalAndAnomaly=X_NormalAndAnomaly.reshape(-1,1,41) # 改变形状适应模型的input_size\n",
    "X_NormalAndAnomaly,_,_= create_dataset(X_NormalAndAnomaly )"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_NormalAndAnomaly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_NormalAndAnomaly\u001B[38;5;241m=\u001B[39m\u001B[43mX_NormalAndAnomaly\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m41\u001B[39m) \u001B[38;5;66;03m# 改变形状适应模型的input_size\u001B[39;00m\n\u001B[1;32m      2\u001B[0m X_NormalAndAnomaly,_,_\u001B[38;5;241m=\u001B[39m create_dataset(X_NormalAndAnomaly )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_NormalAndAnomaly' is not defined"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.962633Z",
     "start_time": "2024-07-01T13:30:18.952063Z"
    }
   },
   "source": [
    "_,_, losses = predict(model, X_NormalAndAnomaly)  # losses中包含了正常数据的重构误差也包含了异常数据的重构误差"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_NormalAndAnomaly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m _,_, losses \u001B[38;5;241m=\u001B[39m predict(model, \u001B[43mX_NormalAndAnomaly\u001B[49m)  \u001B[38;5;66;03m# losses中包含了正常数据的重构误差也包含了异常数据的重构误差\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_NormalAndAnomaly' is not defined"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:18.993389Z",
     "start_time": "2024-07-01T13:30:18.984904Z"
    }
   },
   "source": [
    "\n",
    "real_normal_count=0\n",
    "real_anomal_count=0\n",
    "y=[]\n",
    "Y_NormalAndAnomaly\n",
    "for i in range(0,len(Y_NormalAndAnomaly)):\n",
    "    y.append(Y_NormalAndAnomaly[i])\n",
    "    #print(Y_NormalAndAnomaly[i])\n",
    "    if Y_NormalAndAnomaly[i]==\"normal\":\n",
    "        real_normal_count=real_normal_count+1\n",
    "    if Y_NormalAndAnomaly[i]==\"anomaly\":\n",
    "        real_anomal_count=real_anomal_count+1\n",
    "print(real_normal_count)   # df2中正常数据的数量\n",
    "print(real_anomal_count)  # df2中异常数据的数量\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_NormalAndAnomaly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m real_anomal_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      3\u001B[0m y\u001B[38;5;241m=\u001B[39m[]\n\u001B[0;32m----> 4\u001B[0m \u001B[43mY_NormalAndAnomaly\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(Y_NormalAndAnomaly)):\n\u001B[1;32m      6\u001B[0m     y\u001B[38;5;241m.\u001B[39mappend(Y_NormalAndAnomaly[i])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Y_NormalAndAnomaly' is not defined"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.018489Z",
     "start_time": "2024-07-01T13:30:19.007673Z"
    }
   },
   "source": [
    "FPR=[]\n",
    "TPR=[]\n",
    "labels=y\n",
    "threshold_range=np.linspace(0.1,12,1000)  #  阈值区间划分\n",
    "for t in threshold_range:\n",
    "    judge=[]\n",
    "#     print(t)\n",
    "    for i in range(0,len(losses)):\n",
    "        if losses[i]<=t:\n",
    "            judge.append(\"normal\")\n",
    "        else:\n",
    "            judge.append(\"anomaly\")\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    #print(judge[0:100])\n",
    "    for x1,y1 in zip(labels,judge):\n",
    "        if x1==\"normal\" and y1==\"normal\":\n",
    "            TP=TP+1\n",
    "        elif x1==\"anomaly\" and y1==\"anomaly\":\n",
    "            TN=TN+1\n",
    "        elif x1==\"normal\" and y1==\"anomaly\":\n",
    "            FN=FN+1\n",
    "        elif x1==\"anomaly\" and y1==\"normal\":\n",
    "            FP=FP+1\n",
    "      \n",
    "    TPR.append(TP/(TP+FN)) # 预测为正且实际为正的样本占所有正例样本的比例。\n",
    "    FPR.append(FP/(FP+TN)) # 预测为正但实际为负的样本占所有负例样本的比例\n",
    "    \n",
    "            \n",
    "    "
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m     judge\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#     print(t)\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(\u001B[43mlosses\u001B[49m)):\n\u001B[1;32m      9\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m losses[i]\u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39mt:\n\u001B[1;32m     10\u001B[0m             judge\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormal\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'losses' is not defined"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.176162Z",
     "start_time": "2024-07-01T13:30:19.036600Z"
    }
   },
   "source": [
    "plt.title('ROC ')  # 绘制ROC曲线  横轴为fpr  纵轴为tpr\n",
    "x1=np.linspace(0,1,1000)\n",
    "y1=np.linspace(0,1,1000)\n",
    "plt.plot(FPR,TPR,color=\"red\")\n",
    "plt.plot(x1,y1,color=\"blue\")\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.show()\n",
    "plt.savefig(\"7.svg\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"408.10125pt\" height=\"325.986375pt\" viewBox=\"0 0 408.10125 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-07-01T21:30:19.096928</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.9.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 408.10125 325.986375 \nL 408.10125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \nL 400.90125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 60.013977 288.430125 \nL 60.013977 22.318125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(52.062415 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 124.944886 288.430125 \nL 124.944886 22.318125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(116.993324 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 189.875795 288.430125 \nL 189.875795 22.318125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(181.924233 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 254.806705 288.430125 \nL 254.806705 22.318125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(246.855142 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 319.737614 288.430125 \nL 319.737614 22.318125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(311.786051 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 384.668523 288.430125 \nL 384.668523 22.318125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(376.71696 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- fpr -->\n     <g style=\"fill: #262626\" transform=\"translate(215.351406 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"35.205078\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"98.681641\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 43.78125 276.334125 \nL 400.90125 276.334125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 280.133344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 43.78125 227.950125 \nL 400.90125 227.950125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 231.749344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 43.78125 179.566125 \nL 400.90125 179.566125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 183.365344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 43.78125 131.182125 \nL 400.90125 131.182125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 134.981344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 43.78125 82.798125 \nL 400.90125 82.798125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 86.597344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <path d=\"M 43.78125 34.414125 \nL 400.90125 34.414125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(20.878125 38.213344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- tpr -->\n     <g style=\"fill: #262626\" transform=\"translate(14.798438 162.563969) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"102.685547\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\"/>\n   <g id=\"line2d_14\">\n    <path d=\"M 60.013977 276.334125 \nL 384.668523 34.414125 \nL 384.668523 34.414125 \n\" clip-path=\"url(#pe642995dae)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 288.430125 \nL 43.78125 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.90125 288.430125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- ROC  -->\n    <g style=\"fill: #262626\" transform=\"translate(207.3525 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1225 4090 567 \nQ 3503 -91 2522 -91 \nQ 1538 -91 948 565 \nQ 359 1222 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-4f\" x=\"69.482422\"/>\n     <use xlink:href=\"#DejaVuSans-43\" x=\"148.193359\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"218.017578\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe642995dae\">\n   <rect x=\"43.78125\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.186127Z",
     "start_time": "2024-07-01T13:30:19.179095Z"
    }
   },
   "source": [
    "# ROC曲线中离（0，1）点最近的点所代表的阈值是分类效果最好的 为求得这个阈值 可以用ROC曲线上面的点到\n",
    "# 直线y=x这条直线上的距离来反映  距离越大  阈值对于二分类的效果就越好\n",
    "dis=0\n",
    "i=-1\n",
    "maxIndex=-1\n",
    "for x_fpr,y_tpr in zip(FPR,TPR):\n",
    "    i=i+1\n",
    "    newDis=np.abs(x_fpr*1-y_tpr*1+0)/np.sqrt(4)\n",
    "    if newDis>dis:\n",
    "        dis=newDis\n",
    "        maxIndex=i\n",
    "        \n",
    "threshold_range[maxIndex]    "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.192793Z",
     "start_time": "2024-07-01T13:30:19.187943Z"
    }
   },
   "source": [
    "THRESHOLD=threshold_range[maxIndex]   # 最佳阈值"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.308793Z",
     "start_time": "2024-07-01T13:30:19.300177Z"
    }
   },
   "source": [
    "# 正常测试集的准确率\n",
    "correct = sum(l <= THRESHOLD for l in pred_losses1)\n",
    "print(f'Correct normal predictions: {correct}/{len(test_normal_dataset)}')\n",
    "print('Accuracy:',(correct/len(test_normal_dataset)))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_losses1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 正常测试集的准确率\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(l \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m THRESHOLD \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpred_losses1\u001B[49m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCorrect normal predictions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcorrect\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(test_normal_dataset)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy:\u001B[39m\u001B[38;5;124m'\u001B[39m,(correct\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_normal_dataset)))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pred_losses1' is not defined"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.375187Z",
     "start_time": "2024-07-01T13:30:19.365258Z"
    }
   },
   "source": [
    "# 异常常测试集的准确率\n",
    "correct = sum(l >= THRESHOLD for l in pred_losses2)\n",
    "print(f'Correct anormaly predictions: {correct}/{len(anomaly_dataset)}')\n",
    "print('Accuracy:',(correct/len(anomaly_dataset)))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_losses2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 异常常测试集的准确率\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(l \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m THRESHOLD \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpred_losses2\u001B[49m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCorrect anormaly predictions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcorrect\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(anomaly_dataset)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy:\u001B[39m\u001B[38;5;124m'\u001B[39m,(correct\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(anomaly_dataset)))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pred_losses2' is not defined"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.481426Z",
     "start_time": "2024-07-01T13:30:19.469450Z"
    }
   },
   "source": [
    "# df2（正常异常混合数据）的检测准确率\n",
    "normal_num=0\n",
    "anomaly_num=0\n",
    "detect_ans=[]\n",
    "for i in range(0,len(losses)):\n",
    "    if losses[i]<=THRESHOLD:\n",
    "        detect_ans.append(\"normal\")\n",
    "        if y[i]==\"normal\":\n",
    "              normal_num=normal_num+1\n",
    "        #print(\"正常:\",i)\n",
    "     \n",
    "    if losses[i]>THRESHOLD:\n",
    "        detect_ans.append(\"anomaly\")\n",
    "        if y[i]!=\"normal\":\n",
    "            anomaly_num=anomaly_num+1\n",
    "       # print(\"异常:\",i)\n",
    "\n",
    "print(normal_num,\"/\",real_normal_count)   \n",
    "print(\"正常数据检测准确率\",normal_num/real_normal_count)\n",
    "print(anomaly_num,\"/\",real_anomal_count)\n",
    "print(\"异常数据检测准确率\",anomaly_num/real_anomal_count)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m anomaly_num\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      4\u001B[0m detect_ans\u001B[38;5;241m=\u001B[39m[]\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(\u001B[43mlosses\u001B[49m)):\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m losses[i]\u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39mTHRESHOLD:\n\u001B[1;32m      7\u001B[0m         detect_ans\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormal\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'losses' is not defined"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.530989Z",
     "start_time": "2024-07-01T13:30:19.522319Z"
    }
   },
   "source": [
    "# 将预测结果以DataFrame的形式展现\n",
    "loss=losses\n",
    "thresholdlist=[THRESHOLD for i in range(0,len(loss))]\n",
    "labels=y\n",
    "judge=detect_ans\n",
    "TF_state=[]\n",
    "for x1,y1 in zip(labels,judge):\n",
    "    if x1==y1:\n",
    "        TF_state.append(\"√\")\n",
    "    else:\n",
    "        TF_state.append(\"×\")\n",
    "data={\"loss\":loss,\"threshold\":thresholdlist,\"predict\":judge,\"labels\":labels,\"T/F?\":TF_state}\n",
    "result=pd.DataFrame(data)\n",
    "result.head(50)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 将预测结果以DataFrame的形式展现\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m loss\u001B[38;5;241m=\u001B[39m\u001B[43mlosses\u001B[49m\n\u001B[1;32m      3\u001B[0m thresholdlist\u001B[38;5;241m=\u001B[39m[THRESHOLD \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(loss))]\n\u001B[1;32m      4\u001B[0m labels\u001B[38;5;241m=\u001B[39my\n",
      "\u001B[0;31mNameError\u001B[0m: name 'losses' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.548940Z",
     "start_time": "2024-07-01T13:30:19.538160Z"
    }
   },
   "source": [
    "# 对于df2数据计算准确率、精确率、召回率、f1分数这四个指标\n",
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "thread_range=np.linspace(0,12,1000)\n",
    "for x,y in zip(labels,judge):\n",
    "    if x==y:\n",
    "        if x==\"normal\":\n",
    "            TP=TP+1\n",
    "        else:\n",
    "            TN=TN+1\n",
    "    else:\n",
    "        if x==\"normal\":  # 把正常的判断成了不正常的\n",
    "            FP=FP+1\n",
    "        else:   # 把不正常的判断成了正常的\n",
    "            FN=FN+1  \n",
    "\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)  # 准确率  所有的预测正确（正类负类）的占总的比重\n",
    "precision=TP/(TP+FP)  #  精确率  预测为正样本的结果中，我们有多少把握可以预测正确\n",
    "recall=TP/(TP+FN)   # 召回率  在实际为正的样本中被预测为正样本的概率\n",
    "f1=(2*TP)/(2*TP+FP+FN)\n",
    "print(\"准确率:\",accuracy)\n",
    "print(\"精确率:\",precision)\n",
    "print(\"召回率:\",recall)\n",
    "print(\"f1分数:\",f1)\n"
   ],
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:   \u001B[38;5;66;03m# 把不正常的判断成了正常的\u001B[39;00m\n\u001B[1;32m     17\u001B[0m             FN\u001B[38;5;241m=\u001B[39mFN\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m  \n\u001B[0;32m---> 19\u001B[0m accuracy\u001B[38;5;241m=\u001B[39m\u001B[43m(\u001B[49m\u001B[43mTP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mTN\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mTN\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mFP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mFN\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 准确率  所有的预测正确（正类负类）的占总的比重\u001B[39;00m\n\u001B[1;32m     20\u001B[0m precision\u001B[38;5;241m=\u001B[39mTP\u001B[38;5;241m/\u001B[39m(TP\u001B[38;5;241m+\u001B[39mFP)  \u001B[38;5;66;03m#  精确率  预测为正样本的结果中，我们有多少把握可以预测正确\u001B[39;00m\n\u001B[1;32m     21\u001B[0m recall\u001B[38;5;241m=\u001B[39mTP\u001B[38;5;241m/\u001B[39m(TP\u001B[38;5;241m+\u001B[39mFN)   \u001B[38;5;66;03m# 召回率  在实际为正的样本中被预测为正样本的概率\u001B[39;00m\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 实验第2部分使用SVM进行分类\n",
    "df2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.598320Z",
     "start_time": "2024-07-01T13:30:19.588756Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 训练集测试集分割\n",
    "X_train,X_test,y_train,y_test=train_test_split(df2.loc[:,df2.columns!=\"'class'\"],df2[\"'class'\"],stratify=df2[\"'class'\"],random_state=66)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 训练集测试集分割\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m X_train,X_test,y_train,y_test\u001B[38;5;241m=\u001B[39mtrain_test_split(\u001B[43mdf2\u001B[49m\u001B[38;5;241m.\u001B[39mloc[:,df2\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m!=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m],df2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m],stratify\u001B[38;5;241m=\u001B[39mdf2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m],random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m66\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df2' is not defined"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.627772Z",
     "start_time": "2024-07-01T13:30:19.616010Z"
    }
   },
   "source": [
    "# 将label离散数值（normal anomaly）转化成数字0 1\n",
    "y_train_list_compress=y_train.to_list()\n",
    "y_train_label_compress=[0 if y_train_list_compress[i]==\"normal\" else 1 for i in range(0,len(y_train_list_compress))]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 将label离散数值（normal anomaly）转化成数字0 1\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m y_train_list_compress\u001B[38;5;241m=\u001B[39m\u001B[43my_train\u001B[49m\u001B[38;5;241m.\u001B[39mto_list()\n\u001B[1;32m      3\u001B[0m y_train_label_compress\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y_train_list_compress[i]\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormal\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(y_train_list_compress))]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.703404Z",
     "start_time": "2024-07-01T13:30:19.692279Z"
    }
   },
   "source": [
    "# 输出训练集测试集的形状\n",
    "print(X_train.shape,\"  \",type(X_train))\n",
    "print(X_test.shape,\"  \",type(X_test))\n",
    "print(y_train.shape,\"  \",type(y_train))\n",
    "print(y_test.shape,\"  \",type(y_test))\n",
    "X_train"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 输出训练集测试集的形状\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mX_train\u001B[49m\u001B[38;5;241m.\u001B[39mshape,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;28mtype\u001B[39m(X_train))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(X_test\u001B[38;5;241m.\u001B[39mshape,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;28mtype\u001B[39m(X_test))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_train\u001B[38;5;241m.\u001B[39mshape,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;28mtype\u001B[39m(y_train))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.751799Z",
     "start_time": "2024-07-01T13:30:19.734918Z"
    }
   },
   "source": [
    "from sklearn import preprocessing\n",
    "z_scaler= preprocessing.StandardScaler()\n",
    "X_train_scaler=z_scaler.fit_transform(X_train)\n",
    "X_test_scaler=z_scaler.fit_transform(X_test)\n",
    "\n",
    "m_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_scaler = m_scaler.fit_transform(X_train_scaler) \n",
    "X_test_scaler=m_scaler.fit_transform(X_test_scaler)\n",
    "# 标准化  最大化最小化数据"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m preprocessing\n\u001B[1;32m      2\u001B[0m z_scaler\u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mStandardScaler()\n\u001B[0;32m----> 3\u001B[0m X_train_scaler\u001B[38;5;241m=\u001B[39mz_scaler\u001B[38;5;241m.\u001B[39mfit_transform(\u001B[43mX_train\u001B[49m)\n\u001B[1;32m      4\u001B[0m X_test_scaler\u001B[38;5;241m=\u001B[39mz_scaler\u001B[38;5;241m.\u001B[39mfit_transform(X_test)\n\u001B[1;32m      6\u001B[0m m_scaler \u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mMinMaxScaler()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.854572Z",
     "start_time": "2024-07-01T13:30:19.844349Z"
    }
   },
   "source": [
    "X_train_scaler=X_train_scaler.reshape(58887,1,41) # 使得输入的数据形状适合模型的input_size\n",
    "X_test_scaler=X_test_scaler.reshape(19630,1,41)\n",
    "X_train_scaler,_,_=create_dataset(X_train_scaler)\n",
    "X_test_scaler,_,_=create_dataset(X_test_scaler)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_train_scaler\u001B[38;5;241m=\u001B[39m\u001B[43mX_train_scaler\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m58887\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m41\u001B[39m) \u001B[38;5;66;03m# 使得输入的数据形状适合模型的input_size\u001B[39;00m\n\u001B[1;32m      2\u001B[0m X_test_scaler\u001B[38;5;241m=\u001B[39mX_test_scaler\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m19630\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m41\u001B[39m)\n\u001B[1;32m      3\u001B[0m X_train_scaler,_,_\u001B[38;5;241m=\u001B[39mcreate_dataset(X_train_scaler)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler' is not defined"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.912675Z",
     "start_time": "2024-07-01T13:30:19.899314Z"
    }
   },
   "source": [
    "# 使用模型获得压缩后的训练数据和测试数据\n",
    "X_train_scaler_compressed,_,_=predict(model,X_train_scaler)\n",
    "X_test_scaler_compressed,_,_=predict(model,X_test_scaler)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 使用模型获得压缩后的训练数据和测试数据\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X_train_scaler_compressed,_,_\u001B[38;5;241m=\u001B[39mpredict(model,\u001B[43mX_train_scaler\u001B[49m)\n\u001B[1;32m      3\u001B[0m X_test_scaler_compressed,_,_\u001B[38;5;241m=\u001B[39mpredict(model,X_test_scaler)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler' is not defined"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.977377Z",
     "start_time": "2024-07-01T13:30:19.968196Z"
    }
   },
   "source": [
    "# SVM使用核函数为rbf \n",
    "from sklearn.svm import  SVC\n",
    "svc=SVC(C=0.85, kernel='rbf', degree=3)\n",
    "svc.fit(X_train_scaler_compressed,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_scaler_compressed,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_scaler_compressed,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler_compressed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msvm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m  SVC\n\u001B[1;32m      3\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrbf\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_scaler_compressed\u001B[49m,y_train)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_scaler_compressed,y_train))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_scaler_compressed,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler_compressed' is not defined"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:19.996335Z",
     "start_time": "2024-07-01T13:30:19.989425Z"
    }
   },
   "source": [
    "judge=svc.predict(X_test_scaler_compressed) # 预测的标签\n",
    "labels=y_test # 实际标签"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_scaler_compressed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m judge\u001B[38;5;241m=\u001B[39msvc\u001B[38;5;241m.\u001B[39mpredict(\u001B[43mX_test_scaler_compressed\u001B[49m) \u001B[38;5;66;03m# 预测的标签\u001B[39;00m\n\u001B[1;32m      2\u001B[0m labels\u001B[38;5;241m=\u001B[39my_test \u001B[38;5;66;03m# 实际标签\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_test_scaler_compressed' is not defined"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.045810Z",
     "start_time": "2024-07-01T13:30:20.033248Z"
    }
   },
   "source": [
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "thread_range=np.linspace(0,12,1000)\n",
    "for x,y in zip(labels,judge):\n",
    "    if x==y:\n",
    "        if x==\"normal\":\n",
    "            TP=TP+1\n",
    "        else:\n",
    "            TN=TN+1\n",
    "    else:\n",
    "        if x==\"normal\":  # 把正常的判断成了不正常的\n",
    "            FP=FP+1\n",
    "        else:   # 把不正常的判断成了正常的\n",
    "            FN=FN+1  \n",
    "\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)  # 准确率  所有的预测正确（正类负类）的占总的比重\n",
    "precision=TP/(TP+FP)  #  精确率  预测为正样本的结果中，我们有多少把握可以预测正确\n",
    "recall=TP/(TP+FN)   # 召回率  在实际为正的样本中被预测为正样本的概率\n",
    "f1=(2*TP)/(2*TP+FP+FN)\n",
    "print(\"准确率:\",accuracy)\n",
    "print(\"精确率:\",precision)\n",
    "print(\"召回率:\",recall)\n",
    "print(\"f1分数:\",f1)\n"
   ],
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:   \u001B[38;5;66;03m# 把不正常的判断成了正常的\u001B[39;00m\n\u001B[1;32m     16\u001B[0m             FN\u001B[38;5;241m=\u001B[39mFN\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m  \n\u001B[0;32m---> 18\u001B[0m accuracy\u001B[38;5;241m=\u001B[39m\u001B[43m(\u001B[49m\u001B[43mTP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mTN\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mTN\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mFP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mFN\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 准确率  所有的预测正确（正类负类）的占总的比重\u001B[39;00m\n\u001B[1;32m     19\u001B[0m precision\u001B[38;5;241m=\u001B[39mTP\u001B[38;5;241m/\u001B[39m(TP\u001B[38;5;241m+\u001B[39mFP)  \u001B[38;5;66;03m#  精确率  预测为正样本的结果中，我们有多少把握可以预测正确\u001B[39;00m\n\u001B[1;32m     20\u001B[0m recall\u001B[38;5;241m=\u001B[39mTP\u001B[38;5;241m/\u001B[39m(TP\u001B[38;5;241m+\u001B[39mFN)   \u001B[38;5;66;03m# 召回率  在实际为正的样本中被预测为正样本的概率\u001B[39;00m\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.071085Z",
     "start_time": "2024-07-01T13:30:20.062357Z"
    }
   },
   "source": [
    "# SVM使用核函数为linear\n",
    "svc=SVC(C=0.85, kernel='linear', degree=3)\n",
    "svc.fit(X_train_scaler_compressed,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_scaler_compressed,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_scaler_compressed,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler_compressed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SVM使用核函数为linear\u001B[39;00m\n\u001B[1;32m      2\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_scaler_compressed\u001B[49m,y_train)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_scaler_compressed,y_train))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_scaler_compressed,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler_compressed' is not defined"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.122145Z",
     "start_time": "2024-07-01T13:30:20.114156Z"
    }
   },
   "source": [
    "# SVM使用核函数为poly\n",
    "svc=SVC(C=0.85, kernel='poly', degree=3)\n",
    "svc.fit(X_train_scaler_compressed,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_scaler_compressed,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_scaler_compressed,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler_compressed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SVM使用核函数为poly\u001B[39;00m\n\u001B[1;32m      2\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpoly\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_scaler_compressed\u001B[49m,y_train)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_scaler_compressed,y_train))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_scaler_compressed,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler_compressed' is not defined"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.137744Z",
     "start_time": "2024-07-01T13:30:20.130572Z"
    }
   },
   "source": [
    "# SVM使用核函数为sigmoid\n",
    "svc=SVC(C=0.85, kernel='sigmoid', degree=3)\n",
    "svc.fit(X_train_scaler_compressed,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_scaler_compressed,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_scaler_compressed,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler_compressed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SVM使用核函数为sigmoid\u001B[39;00m\n\u001B[1;32m      2\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_scaler_compressed\u001B[49m,y_train)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_scaler_compressed,y_train))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_scaler_compressed,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler_compressed' is not defined"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.158267Z",
     "start_time": "2024-07-01T13:30:20.149330Z"
    }
   },
   "source": [
    "y_train=np.array(y_train)\n",
    "a_list=[a[0] for a in X_train_scaler_compressed[0:2000] ]\n",
    "b_list=[b[1] for b in X_train_scaler_compressed[0:2000]]\n",
    "for i in range(2000):\n",
    "    if y_train[i]==\"normal\":\n",
    "        plt.scatter(a_list[i],b_list[i],c=\"r\")\n",
    "    else:\n",
    "        plt.scatter(a_list[i],b_list[i],c=\"b\")\n",
    "        "
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m y_train\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray(\u001B[43my_train\u001B[49m)\n\u001B[1;32m      2\u001B[0m a_list\u001B[38;5;241m=\u001B[39m[a[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m X_train_scaler_compressed[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m2000\u001B[39m] ]\n\u001B[1;32m      3\u001B[0m b_list\u001B[38;5;241m=\u001B[39m[b[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m X_train_scaler_compressed[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m2000\u001B[39m]]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.242769Z",
     "start_time": "2024-07-01T13:30:20.191589Z"
    }
   },
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "##用于可视化图表\n",
    "import matplotlib.pyplot as plt\n",
    "##用于做科学计算\n",
    "import numpy as np\n",
    "##用于做数据分析\n",
    "import pandas as pd\n",
    "##用于加载数据或生成数据等\n",
    "from sklearn import datasets\n",
    "##导入PCA库\n",
    "from sklearn.decomposition import PCA\n",
    "##导入LDA库\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.254483Z",
     "start_time": "2024-07-01T13:30:20.244442Z"
    }
   },
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df2.loc[:,df2.columns!=\"'class'\"],df2[\"'class'\"],stratify=df2[\"'class'\"],random_state=66)\n",
    "z_scaler= preprocessing.StandardScaler()\n",
    "X_train_scaler=z_scaler.fit_transform(X_train)\n",
    "X_test_scaler=z_scaler.fit_transform(X_test)\n",
    "\n",
    "m_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_scaler = m_scaler.fit_transform(X_train_scaler) \n",
    "X_test_scaler=m_scaler.fit_transform(X_test_scaler)\n",
    "X_train\n",
    "# 标准化  最大化最小化数据"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_train,X_test,y_train,y_test\u001B[38;5;241m=\u001B[39mtrain_test_split(\u001B[43mdf2\u001B[49m\u001B[38;5;241m.\u001B[39mloc[:,df2\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m!=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m],df2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m],stratify\u001B[38;5;241m=\u001B[39mdf2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m],random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m66\u001B[39m)\n\u001B[1;32m      2\u001B[0m z_scaler\u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mStandardScaler()\n\u001B[1;32m      3\u001B[0m X_train_scaler\u001B[38;5;241m=\u001B[39mz_scaler\u001B[38;5;241m.\u001B[39mfit_transform(X_train)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df2' is not defined"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.265500Z",
     "start_time": "2024-07-01T13:30:20.255884Z"
    }
   },
   "source": [
    "# 将label离散数值（normal anomaly）转化成数字0 1\n",
    "y_train_list_pca=y_train.to_list()\n",
    "y_train_label_pca=[0 if y_train_list_pca[i]==\"normal\" else 1 for i in range(0,len(y_train_list_pca))]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 将label离散数值（normal anomaly）转化成数字0 1\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m y_train_list_pca\u001B[38;5;241m=\u001B[39m\u001B[43my_train\u001B[49m\u001B[38;5;241m.\u001B[39mto_list()\n\u001B[1;32m      3\u001B[0m y_train_label_pca\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y_train_list_pca[i]\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormal\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(y_train_list_pca))]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.295215Z",
     "start_time": "2024-07-01T13:30:20.287176Z"
    }
   },
   "source": [
    "# 加载PCA模型并训练、降到3维\n",
    "model_pca = PCA(n_components=2)\n",
    "X_train_pca = model_pca.fit(X_train_scaler).transform(X_train_scaler)\n",
    "X_test_pca = model_pca.fit(X_test_scaler).transform(X_test_scaler)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 加载PCA模型并训练、降到3维\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model_pca \u001B[38;5;241m=\u001B[39m PCA(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m X_train_pca \u001B[38;5;241m=\u001B[39m model_pca\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_scaler\u001B[49m)\u001B[38;5;241m.\u001B[39mtransform(X_train_scaler)\n\u001B[1;32m      4\u001B[0m X_test_pca \u001B[38;5;241m=\u001B[39m model_pca\u001B[38;5;241m.\u001B[39mfit(X_test_scaler)\u001B[38;5;241m.\u001B[39mtransform(X_test_scaler)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_scaler' is not defined"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.334262Z",
     "start_time": "2024-07-01T13:30:20.326361Z"
    }
   },
   "source": [
    "# SVM使用核函数为rbf \n",
    "svc=SVC(C=0.85, kernel='rbf', degree=3)\n",
    "svc.fit(X_train_pca,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_pca,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_pca,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SVM使用核函数为rbf \u001B[39;00m\n\u001B[1;32m      2\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrbf\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_pca\u001B[49m,y_train)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_pca,y_train))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_pca,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_pca' is not defined"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.363571Z",
     "start_time": "2024-07-01T13:30:20.356537Z"
    }
   },
   "source": [
    "judge=svc.predict(X_test_pca) # 预测的标签\n",
    "labels=y_test # 实际标签"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m judge\u001B[38;5;241m=\u001B[39msvc\u001B[38;5;241m.\u001B[39mpredict(\u001B[43mX_test_pca\u001B[49m) \u001B[38;5;66;03m# 预测的标签\u001B[39;00m\n\u001B[1;32m      2\u001B[0m labels\u001B[38;5;241m=\u001B[39my_test \u001B[38;5;66;03m# 实际标签\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_test_pca' is not defined"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.417665Z",
     "start_time": "2024-07-01T13:30:20.409678Z"
    }
   },
   "source": [
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "thread_range=np.linspace(0,12,1000)\n",
    "for x,y in zip(labels,judge):\n",
    "    if x==y:\n",
    "        if x==\"normal\":\n",
    "            TP=TP+1\n",
    "        else:\n",
    "            TN=TN+1\n",
    "    else:\n",
    "        if x==\"normal\":  # 把正常的判断成了不正常的\n",
    "            FP=FP+1\n",
    "        else:   # 把不正常的判断成了正常的\n",
    "            FN=FN+1  \n",
    "\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)  # 准确率  所有的预测正确（正类负类）的占总的比重\n",
    "precision=TP/(TP+FP)  #  精确率  预测为正样本的结果中，我们有多少把握可以预测正确\n",
    "recall=TP/(TP+FN)   # 召回率  在实际为正的样本中被预测为正样本的概率\n",
    "f1=(2*TP)/(2*TP+FP+FN)\n",
    "print(\"准确率:\",accuracy)\n",
    "print(\"精确率:\",precision)\n",
    "print(\"召回率:\",recall)\n",
    "print(\"f1分数:\",f1)\n"
   ],
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:   \u001B[38;5;66;03m# 把不正常的判断成了正常的\u001B[39;00m\n\u001B[1;32m     16\u001B[0m             FN\u001B[38;5;241m=\u001B[39mFN\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m  \n\u001B[0;32m---> 18\u001B[0m accuracy\u001B[38;5;241m=\u001B[39m\u001B[43m(\u001B[49m\u001B[43mTP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mTN\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mTN\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mFP\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mFN\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 准确率  所有的预测正确（正类负类）的占总的比重\u001B[39;00m\n\u001B[1;32m     19\u001B[0m precision\u001B[38;5;241m=\u001B[39mTP\u001B[38;5;241m/\u001B[39m(TP\u001B[38;5;241m+\u001B[39mFP)  \u001B[38;5;66;03m#  精确率  预测为正样本的结果中，我们有多少把握可以预测正确\u001B[39;00m\n\u001B[1;32m     20\u001B[0m recall\u001B[38;5;241m=\u001B[39mTP\u001B[38;5;241m/\u001B[39m(TP\u001B[38;5;241m+\u001B[39mFN)   \u001B[38;5;66;03m# 召回率  在实际为正的样本中被预测为正样本的概率\u001B[39;00m\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SVM使用核函数为linear\n",
    "svc=SVC(C=0.85, kernel='linear', degree=3)\n",
    "svc.fit(X_train_pca,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_pca,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_pca,y_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.440907Z",
     "start_time": "2024-07-01T13:30:20.433565Z"
    }
   },
   "source": [
    "# SVM使用核函数为poly\n",
    "svc=SVC(C=0.85, kernel='poly', degree=3)\n",
    "svc.fit(X_train_pca,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_pca,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_pca,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SVM使用核函数为poly\u001B[39;00m\n\u001B[1;32m      2\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpoly\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_pca\u001B[49m,y_train)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_pca,y_train))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_pca,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_pca' is not defined"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.475838Z",
     "start_time": "2024-07-01T13:30:20.468482Z"
    }
   },
   "source": [
    "# SVM使用核函数为sigmoid\n",
    "svc=SVC(C=0.85, kernel='sigmoid', degree=3)\n",
    "svc.fit(X_train_pca,y_train)\n",
    "print(\"训练集准确率： \",svc.score(X_train_pca,y_train))\n",
    "print(\"测试集准确率： \",svc.score(X_test_pca,y_test))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SVM使用核函数为sigmoid\u001B[39;00m\n\u001B[1;32m      2\u001B[0m svc\u001B[38;5;241m=\u001B[39mSVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m, degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_pca\u001B[49m,y_train)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_train_pca,y_train))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集准确率： \u001B[39m\u001B[38;5;124m\"\u001B[39m,svc\u001B[38;5;241m.\u001B[39mscore(X_test_pca,y_test))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_pca' is not defined"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.490368Z",
     "start_time": "2024-07-01T13:30:20.481701Z"
    }
   },
   "source": [
    "y_train=np.array(y_train)\n",
    "a_list=[a[0] for a in X_train_pca[0:2000] ]\n",
    "b_list=[b[1] for b in X_train_pca[0:2000]]\n",
    "for i in range(2000):\n",
    "    if y_train[i]==\"normal\":\n",
    "        plt.scatter(a_list[i],b_list[i],c=\"r\")\n",
    "    else:\n",
    "        plt.scatter(a_list[i],b_list[i],c=\"b\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m y_train\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray(\u001B[43my_train\u001B[49m)\n\u001B[1;32m      2\u001B[0m a_list\u001B[38;5;241m=\u001B[39m[a[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m X_train_pca[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m2000\u001B[39m] ]\n\u001B[1;32m      3\u001B[0m b_list\u001B[38;5;241m=\u001B[39m[b[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m X_train_pca[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m2000\u001B[39m]]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T13:30:20.492308Z",
     "start_time": "2024-07-01T13:30:20.491212Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
